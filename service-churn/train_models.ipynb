{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e95b65",
   "metadata": {},
   "source": [
    "#  Vyapar AI - Model Training Pipeline\n",
    "\n",
    "This notebook generates synthetic business data and trains 4 machine learning models for the Vyapar AI Microservice.\n",
    "\n",
    "**Models Trained:**\n",
    "1.  **Churn Prediction** (Logistic Regression) - Predicts customer risk.\n",
    "2.  **Inventory Forecasting** (Linear Regression) - Predicts restock needs.\n",
    "3.  **Lead Scoring** (Random Forest) - Classifies sales leads.\n",
    "4.  **Expense Fraud Detection** (Isolation Forest) - Detects anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5683f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment Ready. Model directory created.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create directory to store models\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "print(\"âœ… Environment Ready. Model directory created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa014f65",
   "metadata": {},
   "source": [
    "## 1. Customer Churn Prediction\n",
    "* **Type:** Classification\n",
    "* **Algorithm:** Logistic Regression\n",
    "* **Input Features:** Days Inactive, Support Tickets, Monthly Bill\n",
    "* **Target:** 0 (Stay), 1 (Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d40878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Churn Model Trained. Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Generate Synthetic Data\n",
    "X_churn = np.random.rand(1000, 3)\n",
    "X_churn[:, 0] = X_churn[:, 0] * 100  # Days Inactive (0-100)\n",
    "X_churn[:, 1] = X_churn[:, 1] * 10   # Tickets (0-10)\n",
    "X_churn[:, 2] = X_churn[:, 2] * 5000 # Bill (0-5000)\n",
    "\n",
    "y_churn = []\n",
    "for x in X_churn:\n",
    "    # Logic: High inactivity (>40) OR High tickets (>5) -> High Churn Risk\n",
    "    prob = 0.1\n",
    "    if x[0] > 40: prob += 0.5\n",
    "    if x[1] > 5: prob += 0.3\n",
    "    y_churn.append(1 if np.random.rand() < prob else 0)\n",
    "\n",
    "# Train Model\n",
    "clf_churn = LogisticRegression()\n",
    "clf_churn.fit(X_churn, y_churn)\n",
    "joblib.dump(clf_churn, \"models/churn_model.pkl\")\n",
    "\n",
    "print(f\"âœ… Churn Model Trained. Accuracy: {clf_churn.score(X_churn, y_churn):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d245fe3",
   "metadata": {},
   "source": [
    "## 2. Inventory Health Forecasting\n",
    "* **Type:** Regression\n",
    "* **Algorithm:** Linear Regression\n",
    "* **Input Features:** Current Stock, Daily Sales Average\n",
    "* **Target:** Recommended Restock Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535efcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inventory Model Trained\n"
     ]
    }
   ],
   "source": [
    "X_inv = np.random.rand(1000, 2)\n",
    "X_inv[:, 0] = X_inv[:, 0] * 100 # Stock (0-100)\n",
    "X_inv[:, 1] = X_inv[:, 1] * 20  # Daily Sales (0-20)\n",
    "\n",
    "y_inv = []\n",
    "for x in X_inv:\n",
    "    stock, sales = x[0], x[1]\n",
    "    # Logic: If stock covers less than 7 days, restock needed\n",
    "    days_left = stock / (sales + 0.1)\n",
    "    if days_left < 7:\n",
    "        y_inv.append((10 - days_left) * sales) # Restock to reach 10 days coverage\n",
    "    else:\n",
    "        y_inv.append(0)\n",
    "\n",
    "reg_inv = LinearRegression()\n",
    "reg_inv.fit(X_inv, y_inv)\n",
    "joblib.dump(reg_inv, \"models/inventory_model.pkl\")\n",
    "print(\"âœ… Inventory Model Trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5293cf",
   "metadata": {},
   "source": [
    "## 3. Sales Lead Scoring\n",
    "* **Type:** Classification\n",
    "* **Algorithm:** Random Forest Classifier\n",
    "* **Input Features:** Budget, Urgency (1-10)\n",
    "* **Target:** 0 (Cold Lead), 1 (Hot Lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31304720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Lead Model Trained\n"
     ]
    }
   ],
   "source": [
    "X_lead = np.random.rand(1000, 2)\n",
    "X_lead[:, 0] = X_lead[:, 0] * 100000 # Budget\n",
    "X_lead[:, 1] = X_lead[:, 1] * 10     # Urgency\n",
    "\n",
    "y_lead = []\n",
    "for x in X_lead:\n",
    "    # Logic: High budget OR High urgency = Hot Lead\n",
    "    if x[0] > 50000 or x[1] > 7:\n",
    "        y_lead.append(1)\n",
    "    else:\n",
    "        y_lead.append(0)\n",
    "\n",
    "clf_lead = RandomForestClassifier(n_estimators=10)\n",
    "clf_lead.fit(X_lead, y_lead)\n",
    "joblib.dump(clf_lead, \"models/lead_model.pkl\")\n",
    "print(\"âœ… Lead Model Trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b19ff",
   "metadata": {},
   "source": [
    "## 4. Expense Audit (Anomaly Detection)\n",
    "* **Type:** Unsupervised Learning (Anomaly Detection)\n",
    "* **Algorithm:** Isolation Forest\n",
    "* **Input Features:** Transaction Amount\n",
    "* **Target:** -1 (Anomaly/Fraud), 1 (Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a44f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Expense Model Trained\n"
     ]
    }
   ],
   "source": [
    "# Generate \"Normal\" transactions (< 5000)\n",
    "X_exp_normal = np.random.rand(800, 1) * 5000\n",
    "# Generate \"Fraud\" transactions (5000 - 10000)\n",
    "X_exp_anomaly = np.random.rand(200, 1) * 5000 + 5000 \n",
    "X_exp = np.concatenate([X_exp_normal, X_exp_anomaly])\n",
    "\n",
    "clf_exp = IsolationForest(contamination=0.2, random_state=42)\n",
    "clf_exp.fit(X_exp)\n",
    "joblib.dump(clf_exp, \"models/expense_model.pkl\")\n",
    "print(\"âœ… Expense Model Trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(\"models\", 'zip', \"models\")\n",
    "print(\"ðŸ“¦ Models zipped successfully as 'models.zip'\")\n",
    "\n",
    "# If running in Google Colab, uncomment below to download:\n",
    "from google.colab import files\n",
    "files.download(\"models.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d74353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
